{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Recurrent Neural Networks\n",
    "\n",
    "## The structure of the lecture:\n",
    "- Why RNNs & NLP matter\n",
    "- RNNs: An introduction\n",
    "- RNNs Under the Hood (and architectural variations)\n",
    "- NLP: Why we use RNNs\n",
    "- Classifying sentiment: A coded example\n",
    "- Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Why RNNs & NLP matter\n",
    "\n",
    "üìà Recurrent Neural Networks are Neural Networks specifically designed to deal with **sequences** as input data, i.e. **observations repeated throughout time**.\n",
    "\n",
    "### Example 1: Prediction of future stock market values and trends\n",
    "\n",
    "![ex_1](pics/example_1.png)\n",
    "\n",
    "### Example 2: Video prediction\n",
    "\n",
    "üé• Videos = sequences of images/frames\n",
    "\n",
    "üëâ Why not predicting the next image(s)?\n",
    "\n",
    "![ex_2](pics/example_2.png)\n",
    "\n",
    "### Example 3: Predicting the next word - Natural Language Processing\n",
    "\n",
    "Recurrent Networks are massively used for text!\n",
    "\n",
    "![ex_3](pics/example_3.png)\n",
    "\n",
    "\n",
    "### NLP: Text classification, such as sentiment analysis\n",
    "Classification depending on a word, a sentence, a paragraph, ...\n",
    "\n",
    "![ex_4](pics/example_4.png)\n",
    "\n",
    "The typical setting is sentiment analysis: Classify positive or negative sentences (but also happiness, sadness, joy, anger, ...).\n",
    "\n",
    "### Sequence to Sequence Models\n",
    "\n",
    "Given an input sequence, produce a corresponding output sequence. Typical application is language translation.\n",
    "\n",
    "![ex_5](pics/example_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ RNNs: An introduction\n",
    "\n",
    "Traditional (Statistical) Time Series forecasting can be represented in the following way:\n",
    "\n",
    "![ts_1](pics/ts_1.png)\n",
    "\n",
    "The algorithm would learn from the past values to predict the future values using temporal features such as the trend, the seasonality...\n",
    "\n",
    "üëâ Example: [**ARIMA**](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average) models **recursively** predict the next data points one after the other\n",
    "\n",
    "What follows is a slighly different approach...\n",
    "\n",
    "![dl_framework](pics/dl_frame.png)\n",
    "\n",
    "![rnn_framework](pics/rnn_frame.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/pred_1.png\" width=\"750\"/>\n",
    "\n",
    "<img src=\"pics/pred_2.png\" width=\"820\"/>\n",
    "\n",
    "<img src=\"pics/pred_3.png\" width=\"850\"/>\n",
    "\n",
    "<img src=\"pics/pred_4.png\" width=\"910\"/>\n",
    "\n",
    "<img src=\"pics/pred_5.png\" width=\"930\"/>\n",
    "\n",
    "<img src=\"pics/pred_6.png\" width=\"990\"/>\n",
    "\n",
    "<img src=\"pics/pred_7.png\" width=\"960\"/>\n",
    "\n",
    "<img src=\"pics/pred_8.png\" width=\"920\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/pred_recap.png\" width=\"850\"/>\n",
    "\n",
    "<img src=\"pics/pred_recap_2.png\" width=\"910\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ RNNs Under the Hood\n",
    "\n",
    "<img src=\"pics/rnn_intro.png\" width=\"580\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn_diagramm.png](pics/rnn_diagram.png)\n",
    "\n",
    "**Let's zoom inside this function $f_W$ for one time step**. \n",
    "\n",
    "![rnn_diagramm_2.png](pics/rnn_diagram_2.png)\n",
    "\n",
    "![rnn_intro_2.png](pics/rnn_intro_2.png)\n",
    "\n",
    "![rnn_weight.png](pics/rnn_weight.png)\n",
    "\n",
    "![rnn_note.png](pics/rnn_note.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn_number_units.png](pics/rnn_number_units.png)\n",
    "\n",
    "![rnn_layer.png](pics/rnn_layer.png)\n",
    "\n",
    "![rnn_stack.png](pics/rnn_stack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn_diagramm.png](pics/rnn_diagram.png)\n",
    "\n",
    "<img src=\"pics/rnn_diagram_stack.png\" width=\"1050\"/>\n",
    "\n",
    "![rnn_type.png](pics/rnn_type.png)\n",
    "\n",
    "<img src=\"pics/rnn_lstm_gru.png\" width=\"1050\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ NLP: Why we need RNNs\n",
    "\n",
    "### Because order matters!\n",
    "\n",
    "An obvious example:\n",
    "\n",
    "- \"The teacher inspired the students with a passionate speech about deep learning\"\n",
    "- \"The students inspired the teacher with a passionate speech about deep learning\"\n",
    "\n",
    "A more subtle example:\n",
    "\n",
    "- \"The company hired talented employees and achieved great success.\"\n",
    "- \"The company achieved great success and hired talented employees.\"\n",
    "\n",
    "Let's give ourselves a task to solve by the end of the lecture!\n",
    "\n",
    "Our `X` will be sentences and our `y` will be whether or not those sentences are positive or negative!\n",
    "\n",
    "How do we go about this?\n",
    "\n",
    "\"This movie is the best thing I've seen in my life\" -> ‚úÖ \"I had to leave this film because I was so bored\" -> ‚ùå \"Anything with Nicolas Cage in it is a masterpiece: 5/5\" -> ‚úÖ\n",
    "\n",
    "### How to feed Recurrent Neural Networks with words?\n",
    "\n",
    "![rnn_example.png](pics/rnn_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have to convert words into numbers somehow!\n",
    "\n",
    "**Text** is also a form of **recurrent data**, where a sentence is a sequence of words, each being the observation. For now, let's imagine we can express each **word** as four **numbers** (or a point/ vector in 4-D space). \n",
    "\n",
    "![rnn_example_2.png](pics/rnn_example_2.png)\n",
    "\n",
    "### What will our `X` look like?\n",
    "\n",
    "![rnn_example_3.png](pics/rnn_example_3.png)\n",
    "\n",
    "`X` is just a sequence of observations! Univariate, multivariate, an image, ... The point is that the observation is repeated through time!\n",
    "\n",
    "`X.shape = (N_SEQUENCES, N_OBSERVATIONS, N_FEATURES)`\n",
    "\n",
    "**Warning**: The number of observations can vary from one sequence to another! (This is when you `pad` - we'll get back to that)\n",
    "\n",
    "\n",
    "### First, we'll need tokens\n",
    "\n",
    "Neural networks' can't work directly on words, so you will still need to provide it with tokens.\n",
    "\n",
    "![rnn_example_4.png](pics/rnn_example_4.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 12:54:57.710853: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14 different words in your corpus\n",
      "X_pad.shape (3, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  2.,  3.,  4.,  5.],\n",
       "       [ 0.,  1.,  6.,  7.,  8.,  9.,  2.,  3.],\n",
       "       [ 1., 10., 11., 12.,  1.,  4., 13., 14.]], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "### Let's create some mock data\n",
    "def get_mock_up_data():\n",
    "    sentence_1 = 'This movie was awful'\n",
    "    sentence_2 = 'I loved every moment of this movie!'\n",
    "    sentence_3 = 'I want a refund; I was so bored!'\n",
    "\n",
    "    X = [sentence_1, sentence_2, sentence_3]\n",
    "    y = np.array([0., 1., 0.])\n",
    "\n",
    "    ### Let's tokenize the vocabulary\n",
    "    tk = Tokenizer()\n",
    "    tk.fit_on_texts(X)\n",
    "    vocab_size = len(tk.word_index)\n",
    "    print(f'There are {vocab_size} different words in your corpus')\n",
    "    X_token = tk.texts_to_sequences(X)\n",
    "\n",
    "    ### Pad the inputs\n",
    "    X_pad = pad_sequences(X_token, dtype='float32', padding='pre')\n",
    "\n",
    "    return X_pad, y, vocab_size\n",
    "\n",
    "X_pad, y, vocab_size = get_mock_up_data()\n",
    "print(\"X_pad.shape\", X_pad.shape)\n",
    "X_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn_padding.png](pics/rnn_padding.png)\n",
    "\n",
    "ü§î To\"post\" or to \"pre\"? The eternal question: there's no definitive answer and it varies by architecture, but results seem to lean towards using [\"pre\"](https://pmc.ncbi.nlm.nih.gov/articles/PMC7471694/) (Another resource: [Medium](https://saadsohail5104.medium.com/understanding-padding-in-nlp-types-and-when-to-use-them-bacae6cae401#:~:text=Pre%2DPadding%20(Default)%3A,the%20end%20of%20a%20sequence.))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to make the leap from tokens to vectors\n",
    "\n",
    "We want each word to be represented by a vector `‚Üó` of chosen length. How?\n",
    "\n",
    "### Consider a 2D embedding\n",
    "\n",
    "To further specify the meaning of each word, we add a dimension: we rank them according to their relative abstraction. \n",
    "\n",
    "<img src=\"pics/rnn_2d_embed.png\" width=\"850\"/>\n",
    "\n",
    "We can't differentiate much between \"horse\" and \"killer whale\" :)\n",
    "\n",
    "### Adding a 3rd dimension\n",
    "\n",
    "<img src=\"pics/rnn_3d_embed.png\" width=\"850\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic on words?\n",
    "\n",
    "If we embed correctly, we could dream of performing mathematical operations on the embeddings, which would have meaning in terms of natural language.\n",
    "\n",
    "E.g. we could express the sentence \"Queen is to king as man is to...\" as $V(Queen) - V (King) + V(Man) = ?$\n",
    "\n",
    "<img src=\"pics/word2vec.png\" width=\"300\"/>\n",
    "\n",
    "Here, as the red vectors are similar, we could expect $V(Queen) - V (King) = V(Woman) - V(Man)$\n",
    "\n",
    "So the answer we're looking for might be $Woman$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What makes a good embedding?\n",
    "\n",
    "Semantically close words are mathematically close in this space\n",
    "\n",
    "‚ùóÔ∏è Usually, word embedding spaces are from 30 up to 300 dimensions ‚ùóÔ∏è\n",
    "\n",
    "ü§î But wait ... how do you choose these numbers? Surely we're not scoring all of our words on n difference axes?\n",
    "\n",
    "<img src=\"pics/embeddings_cloud.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two options: learn with `layers.Embedding` or with `Word2Vec`\n",
    "\n",
    "\n",
    "<img src=\"pics/embedding_vs_word2vec_2.png\" width=\"800\"/>\n",
    "\n",
    "\n",
    "üëà The left option allows you to have a representation that is perfectly suited to your task! However, it increases the number of parameters to learn, and thus:\n",
    "\n",
    "- the time of each epoch (more parameters to optimize during back-propagation)\n",
    "- the time to converge (because more parameters to find overall)\n",
    "\n",
    "üëâ On the other hand, word2vec is an unsupervised learning method not specifically designed for your task (may be sub-optimal) but training it is very fast! You will also be able to optimize your RNN faster as you'll have less parameters.\n",
    "\n",
    "- ‚ùó Prefer Word2Vec on small corpus (esp. with transfer learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/first_option.png\" width=\"700\"/>\n",
    "\n",
    "<img src=\"pics/second_option.png\" width=\"1000\"/>\n",
    "\n",
    "üí° We use unsupervised learning to look at the words around each chosen word \n",
    "\n",
    "and assume that these will be relevant to the word we're interested in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead of training it on your training set (especially if it is very small), you can directly load a pretrained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "print(list(gensim.downloader.info()['models'].keys()))\n",
    "\n",
    "model_wiki = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even try out our aforementioned example with code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N.B. Words not in glove-wiki-gigaword-50 will not have vectors computed\n",
    "example_1 = model_wiki[\"queen\"] - model_wiki[\"king\"] + model_wiki[\"man\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.8903914093971252),\n",
       " ('girl', 0.8453726768493652),\n",
       " ('man', 0.8301756381988525),\n",
       " ('her', 0.7845831513404846),\n",
       " ('boy', 0.7763065695762634),\n",
       " ('she', 0.7619765400886536),\n",
       " ('herself', 0.7597628235816956),\n",
       " ('blind', 0.7296755313873291),\n",
       " ('mother', 0.7230339646339417),\n",
       " ('blonde', 0.713614284992218)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wiki.most_similar(example_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about \"good is to evil as cold is to...\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_2 = model_wiki[\"good\"] - model_wiki[\"evil\"] + model_wiki[\"cold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('warm', 0.7870427966117859),\n",
       " ('dry', 0.7643216848373413),\n",
       " ('hot', 0.750431478023529),\n",
       " ('cool', 0.7491166591644287),\n",
       " ('weather', 0.7476345896720886),\n",
       " ('getting', 0.7447267770767212),\n",
       " ('good', 0.7442173361778259),\n",
       " ('cold', 0.7425146102905273),\n",
       " ('low', 0.7231549620628357),\n",
       " ('little', 0.7223491668701172)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wiki.most_similar(example_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Coded example: Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load up our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Set parameters\n",
    "max_features = 10000  # Maximum number of words to get out of our imdb data\n",
    "max_len = 500  # Maximum sequence length\n",
    "embedding_dim = 50  # Dimensionality of word embeddings\n",
    "\n",
    "# Load the IMDb dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to pad üóíÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to a fixed length\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll construct and compile our model üî®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnaud/miniconda3/envs/nlptest/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim, input_length=max_len))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we fit and evaluate üíØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m196/196\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 920ms/step - accuracy: 0.8664 - loss: 0.3285 - val_accuracy: 0.8756 - val_loss: 0.2979\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 230ms/step - accuracy: 0.8742 - loss: 0.3009\n",
      "Test loss: 0.2979\n",
      "Test accuracy: 0.8756\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=1, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! We can predict sentiment with a very high degree of accuracy and minimal pre-processing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Further reading\n",
    "- üìö [Stanford Cheat Sheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)\n",
    "- üìö [Medium - Illustrated Guide to RNN](https://medium.com/data-science/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9)\n",
    "- üìö [Medium - Illustrated Guide to LSTM and GRUs](https://medium.com/data-science/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)\n",
    "- üì∫ [RNN explained with 3*3 matrices - 21min](https://www.youtube.com/watch?v=UNmqTiOnRfg)\n",
    "- üì∫ [RNN & LSTM explained without math - 24min](https://www.youtube.com/watch?v=WCUNPb-5EYI)\n",
    "\n",
    "### Deep Learning courses - videos\n",
    "- [CS224N](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z): Natural Language Processing with Deep Learning by Standford University (recommended)\n",
    "- [92 step-by-step videos](https://www.youtube.com/watch?v=SGZ6BttHMPw&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH) by Hugo Larochelle.\n",
    "- [Deep Learning course](https://www.coursera.org/specializations/deep-learning), by Andrew Ng.\n",
    "- [MIT Introduction to Deep Learning](https://www.youtube.com/playlist?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI), from MIT.\n",
    "\n",
    "### Deep Learning courses - books\n",
    "- [Deep Learning book](https://www.deeplearningbook.org/), by Ian Goodfellow, Yoshua Bengio, Aaron Courville\n",
    "- Deep Learning with Python, by Fran√ßois Chollet231 Lecture on RNN - 1h20 (https://www.youtube.com/watch?v=6niqTuYFZLQ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlptest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
